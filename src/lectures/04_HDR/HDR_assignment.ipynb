{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Assignement - HDR, response function estimation and HDR composition by Debevec method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T21:24:09.538329100Z",
     "start_time": "2023-10-14T21:24:09.400630600Z"
    }
   },
   "outputs": [],
   "source": [
    "import exif\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from copy import copy\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:20:12.327515700Z",
     "start_time": "2023-10-15T10:20:12.055995400Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_images(urls, path):\n",
    "    for idx in range(len(urls)):\n",
    "        print(urls[idx], end='')\n",
    "        r = requests.get(urls[idx], stream=True)\n",
    "        if r.status_code == 200:\n",
    "            with open(os.path.join(path, f'image{idx:02d}.jpg'), 'bw') as f:\n",
    "                # r.raw.decode_content = True\n",
    "                shutil.copyfileobj(r.raw, f)    \n",
    "                print('...OK')\n",
    "        else:\n",
    "                print('...FAIL')\n",
    "\n",
    "def read_images(file_pattern, scale_percent = 100):\n",
    "    files = glob.glob(file_pattern) \n",
    "\n",
    "    imgs = []\n",
    "    t = []\n",
    "\n",
    "    for file in files:\n",
    "        tmp_img = cv2.imread(file) \n",
    "        width = int(tmp_img.shape[1] * scale_percent // 100) \n",
    "        height = int(tmp_img.shape[0] * scale_percent // 100)\n",
    "        dim = (width, height) \n",
    "        imgs.append(cv2.cvtColor(cv2.resize(tmp_img, dim, interpolation = cv2.INTER_AREA), cv2.COLOR_BGR2RGB)) \n",
    "        info = exif.Image(file)\n",
    "        t.append(info.exposure_time) \n",
    "    return (height, width), np.array(imgs), t \n",
    "\n",
    "def get_weights(Z, L):\n",
    "    return np.interp(Z, [0, (L-1)/2, L-1], [0, 1, 0]).flatten() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:20:14.741064500Z",
     "start_time": "2023-10-15T10:20:14.057785600Z"
    }
   },
   "outputs": [],
   "source": [
    "images_urls = ['https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka02.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka03.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka04.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka05.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka06.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka07.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka08.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka09.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka10.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka11.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka12.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka13.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka14.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka15.jpg?raw=true',\n",
    "              ]\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    download_images(images_urls, tempdir)\n",
    "    dim, Z, t = read_images(os.path.join(tempdir, \"*.jpg\"), scale_percent = 1)\n",
    "    \n",
    "print(f'Image shape: {dim}')\n",
    "print(f'Exposure times [s]: {t}')\n",
    "\n",
    "r = Z[:, :, :, 0].flatten() \n",
    "g = Z[:, :, :, 1].flatten() \n",
    "b = Z[:, :, :, 2].flatten() \n",
    "\n",
    "L = 2**8\n",
    "lambda_ = 2 \n",
    "\n",
    "w_r = get_weights(r, L) \n",
    "w_g = get_weights(g, L) \n",
    "w_b = get_weights(b, L) \n",
    "\n",
    "t_ind, Z_ind = np.indices((Z.shape[0], Z.shape[1]*Z.shape[2]))\n",
    "t_ind = t_ind.flatten()\n",
    "E_ind = Z_ind\n",
    "\n",
    "t_vec_r = np.log(np.take(t, t_ind)) * w_r\n",
    "t_vec_g = np.log(np.take(t, t_ind)) * w_g\n",
    "t_vec_b = np.log(np.take(t, t_ind)) * w_b\n",
    "\n",
    "g_vec_r = np.log(r+0.01)\n",
    "g_vec_g = np.log(g+0.01)\n",
    "g_vec_b = np.log(b+0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T00:16:51.398609200Z",
     "start_time": "2023-10-15T00:16:51.371594600Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_exposure(w, g_vec, t_ind, E_ind):\n",
    "    A = np.zeros(((len(g_vec)+1), np.max(E_ind)+1+np.max(t_ind)))\n",
    "    b = np.zeros((len(g_vec)+1))\n",
    "    E_ind = E_ind.flatten()\n",
    "    r_ind = list(range(A.shape[0]-1))\n",
    "    A[r_ind, E_ind.flatten()] = np.sqrt(w)\n",
    "    A[r_ind, t_ind.flatten()+np.max(E_ind)] = np.sqrt(w)\n",
    "    b[:-1] = g_vec*np.sqrt(w)\n",
    "    A[-1, np.max(E_ind)+1] = 1\n",
    "    sol = lsqr(A, b)\n",
    "    return sol[0][:np.max(E_ind)+1], sol[0][np.max(E_ind)+1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_exposure_r, t_est_r = estimate_exposure(w_r, g_vec_r, t_ind, E_ind)\n",
    "E_exposure_g, t_est_g = estimate_exposure(w_g, g_vec_g, t_ind, E_ind)\n",
    "E_exposure_b, t_est_b = estimate_exposure(w_b, g_vec_b, t_ind, E_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Exposure time estimation (red): ', np.exp(t_est_r))\n",
    "print(f'Exposure time estimation (green): ', np.exp(t_est_g))\n",
    "print(f'Exposure time estimation (blue): ', np.exp(t_est_b))\n",
    "print(f'Real exposure time: ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T23:31:34.349820800Z",
     "start_time": "2023-10-14T23:31:34.302823700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_response_debevec(w, L, Z_vec, t_vec, E_ind, lambd):\n",
    "    # YOUR estimate_response_debevec LOGIC HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T09:59:34.608597100Z",
     "start_time": "2023-10-15T09:59:30.231786100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lambda_ = 2\n",
    "g_r, _ = estimate_response_debevec(w_r, 2**8, r, t, Z_ind, lambda_)\n",
    "g_g, _ = estimate_response_debevec(w_g, 2**8, g, t, Z_ind, lambda_)\n",
    "g_b, _ = estimate_response_debevec(w_b, 2**8, b, t, Z_ind, lambda_)\n",
    "plt.plot(g_r, 'r')\n",
    "plt.plot(g_g, 'g')\n",
    "plt.plot(g_b, 'b')\n",
    "plt.title('Estimated camera transfer functions');\n",
    "plt.xlabel('Z')\n",
    "plt.ylabel('g()');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:09:26.824682600Z",
     "start_time": "2023-10-15T10:09:26.414754400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_response(L, g, degree=2):\n",
    "    g_val = []\n",
    "    for idx in range(L):\n",
    "        g_val.append([idx, g[idx]])\n",
    "    g_val = np.array(g_val)\n",
    "    \n",
    "    poly_transform = PolynomialFeatures(degree=degree, include_bias=False).fit(g_val[:,0].reshape((-1,1)))\n",
    "    poly_trans = lambda x: poly_transform.transform(x.reshape((-1,1)))\n",
    "    z_poly = poly_trans(g_val[:,0])\n",
    "    g_model = LinearRegression()\n",
    "    g_model.fit(z_poly, g_val[:,1])\n",
    "    g_model_pred = g_model.predict(poly_trans(g_val[:,0]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(x=g_val[:,0], y=g_val[:,1])\n",
    "    plt.plot(g_model_pred, 'r')\n",
    "    \n",
    "    return g_model_pred\n",
    "\n",
    "g_model_r = fit_response(2**8, g_r, degree=2)\n",
    "plt.title('Camera response function - red chanel')\n",
    "g_model_g = fit_response(2**8, g_g, degree=2)\n",
    "plt.title('Camera response function - green chanel')\n",
    "g_model_b = fit_response(2**8, g_b, degree=2)\n",
    "plt.title('Camera response function - blue chanel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    download_images(images_urls, tempdir)\n",
    "    dim_f, Z_f, t_f = read_images(os.path.join(tempdir, \"*.jpg\"), scale_percent = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:22:23.024825900Z",
     "start_time": "2023-10-15T10:22:21.747401700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def hdr_from_exposure(g, w, Z, t):\n",
    "    w_img = np.sqrt(w.reshape((len(t),-1)))\n",
    "    Z_img = np.interp(Z, list(range(2**8)), g).reshape((len(t),-1))\n",
    "    E = np.zeros(w_img.shape[1], dtype=np.float32)\n",
    "    t = np.log(t)\n",
    "    for idx in range(len(E)):\n",
    "        E[idx] = # YOUR pixel irradiance LOGIC HERE\n",
    "    return E\n",
    "\n",
    "r_f = Z_f[:, :, :, 0].flatten() \n",
    "g_f = Z_f[:, :, :, 1].flatten() \n",
    "b_f = Z_f[:, :, :, 2].flatten() \n",
    "w_r_f = get_weights(r_f, L) \n",
    "w_g_f = get_weights(g_f, L) \n",
    "w_b_f = get_weights(b_f, L) \n",
    "\n",
    "E_r_est = hdr_from_exposure(g_model_r, w_r_f, r_f, t)\n",
    "E_g_est = hdr_from_exposure(g_model_g, w_g_f, g_f, t)\n",
    "E_b_est = hdr_from_exposure(g_model_b, w_b_f, b_f, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:12.192137800Z",
     "start_time": "2023-10-15T10:10:11.905151Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(E_r_est.reshape(dim_f))\n",
    "plt.colorbar()\n",
    "plt.title('Irradiance map - red chanel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:15.015217500Z",
     "start_time": "2023-10-15T10:10:14.774182600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(E_g_est.reshape(dim_f))\n",
    "plt.colorbar()\n",
    "plt.title('Irradiance map - green chanel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:17.415962800Z",
     "start_time": "2023-10-15T10:10:17.167968Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(E_b_est.reshape(dim_f))\n",
    "plt.colorbar()\n",
    "plt.title('Irradiance map - blue chanel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:20.100239600Z",
     "start_time": "2023-10-15T10:10:19.900219600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hdr = np.stack((E_r_est.reshape(dim_f), E_g_est.reshape(dim_f), E_b_est.reshape(dim_f)), axis=-1)\n",
    "plt.imshow(hdr)\n",
    "plt.title('HDR Image - clipped');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:31.208913100Z",
     "start_time": "2023-10-15T10:10:30.879319300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tonemap1 = cv2.createTonemap(gamma=1)\n",
    "res_debevec = tonemap1.process(hdr.copy())\n",
    "res_debevec = np.clip(res_debevec*255, 0, 255).astype('uint8')\n",
    "plt.imshow(res_debevec)\n",
    "plt.title('Generated LDR image by tonemapping');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
