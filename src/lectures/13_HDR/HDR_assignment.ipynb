{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Assignement - HDR, response function estimation and HDR composition by Debevec method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T21:24:09.538329100Z",
     "start_time": "2023-10-14T21:24:09.400630600Z"
    }
   },
   "outputs": [],
   "source": [
    "import exif\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from copy import copy\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:20:12.327515700Z",
     "start_time": "2023-10-15T10:20:12.055995400Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_images(urls, path):\n",
    "    for idx in range(len(urls)):\n",
    "        print(urls[idx], end='')\n",
    "        r = requests.get(urls[idx], stream=True)\n",
    "        if r.status_code == 200:\n",
    "            with open(os.path.join(path, f'image{idx:02d}.jpg'), 'bw') as f:\n",
    "                # r.raw.decode_content = True\n",
    "                shutil.copyfileobj(r.raw, f)    \n",
    "                print('...OK')\n",
    "        else:\n",
    "                print('...FAIL')\n",
    "\n",
    "def read_images(file_pattern, scale_percent = 100):\n",
    "    files = glob.glob(file_pattern) \n",
    "\n",
    "    imgs = []\n",
    "    t = []\n",
    "\n",
    "    for file in files:\n",
    "        tmp_img = cv2.imread(file) \n",
    "        width = int(tmp_img.shape[1] * scale_percent // 100) \n",
    "        height = int(tmp_img.shape[0] * scale_percent // 100)\n",
    "        dim = (width, height) \n",
    "        imgs.append(cv2.cvtColor(cv2.resize(tmp_img, dim, interpolation = cv2.INTER_AREA), cv2.COLOR_BGR2RGB)) \n",
    "        info = exif.Image(file)\n",
    "        t.append(info.exposure_time) \n",
    "    return (height, width), np.array(imgs), t \n",
    "\n",
    "def get_weights(Z, L):\n",
    "    return np.interp(Z, [0, (L-1)/2, L-1], [0, 1, 0]).flatten() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images and prepare vectors/matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:20:14.741064500Z",
     "start_time": "2023-10-15T10:20:14.057785600Z"
    }
   },
   "outputs": [],
   "source": [
    "images_urls = ['https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka02.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka03.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka04.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka05.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka06.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka07.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka08.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka09.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka10.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka11.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka12.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka13.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka14.jpg?raw=true',\n",
    "               'https://github.com/CVUT-FS-12110/Machine-Perception-and-Image-Analysis/blob/master/src/lectures/04_HDR/images/lampicka15.jpg?raw=true',\n",
    "              ]\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    download_images(images_urls, tempdir)\n",
    "    dim, Z, t = read_images(os.path.join(tempdir, \"*.jpg\"), scale_percent = 0.3)\n",
    "\n",
    "sort_index = sorted(range(len(t)), key=lambda k: t[k])\n",
    "t = [t[k] for k in sort_index]\n",
    "Z = Z[sort_index]\n",
    "\n",
    "print(f'Image shape: {dim}')\n",
    "print(f'Exposure times [s]: {t}')\n",
    "\n",
    "r = Z[:, :, :, 0].flatten() \n",
    "g = Z[:, :, :, 1].flatten() \n",
    "b = Z[:, :, :, 2].flatten() \n",
    "\n",
    "# weight vectors\n",
    "w_r = get_weights(r, 2**8) \n",
    "w_g = get_weights(g, 2**8) \n",
    "w_b = get_weights(b, 2**8) \n",
    "\n",
    "# Indices to time vector and images\n",
    "t_ind, Z_ind = np.indices((Z.shape[0], Z.shape[1]*Z.shape[2]))\n",
    "t_ind = t_ind.flatten()\n",
    "E_ind = Z_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate exposure times function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T00:16:51.398609200Z",
     "start_time": "2023-10-15T00:16:51.371594600Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_exposure_time(w, Z, t_ind, Z_ind):\n",
    "    '''\n",
    "    Estimates exposure times assumes the camera response function is identity.\n",
    "\n",
    "    Parameters:\n",
    "    w (float): An array of shape (N,) of weights.\n",
    "    Z (numpy.ndarray): An array of shape (N,) containing the pixel intezities.\n",
    "    t_ind (numpy.ndarray): An array of shape (P, N,) containing the time indices.\n",
    "    Z_ind (numpy.ndarray): An array of shape (P, N,) containing the pixel intensities indices.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: An array of shape (P,) containing the estimated exposure times.\n",
    "\n",
    "    '''\n",
    "    # Z = Z/(L-1)\n",
    "    eps = np.finfo(float).eps\n",
    "    a_rows_count = (np.max(Z_ind) + 1) * (np.max(t_ind) + 1) + 1\n",
    "    A = np.zeros((a_rows_count, np.max(Z_ind) + np.max(t_ind) + 2))\n",
    "    b = np.zeros((a_rows_count))\n",
    "    Z_ind = Z_ind.flatten()\n",
    "    r_ind = list(range(A.shape[0]-1))\n",
    "    A[r_ind, Z_ind.flatten()] = np.sqrt(w)\n",
    "    A[r_ind, t_ind.flatten() + 1 + np.max(Z_ind)] = np.sqrt(w)\n",
    "    b[:-1] = np.log(Z + eps) * np.sqrt(w)\n",
    "    A[-1, np.max(Z_ind) + 1] = 1\n",
    "    sol = lsqr(A, b)\n",
    "    return sol[0][np.max(Z_ind) + 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_est_r = estimate_exposure_time(w_r, r, t_ind, E_ind)\n",
    "t_est_g = estimate_exposure_time(w_g, g, t_ind, E_ind)\n",
    "t_est_b = estimate_exposure_time(w_b, b, t_ind, E_ind)\n",
    "print(np.log(t[0]),t_est_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Exposure time estimation (red): ', np.exp(t_est_r))\n",
    "print(f'Exposure time estimation (green): ', np.exp(t_est_g))\n",
    "print(f'Exposure time estimation (blue): ', np.exp(t_est_b))\n",
    "print(f'Real exposure time: ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate inverse response function - YOUR TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T23:31:34.349820800Z",
     "start_time": "2023-10-14T23:31:34.302823700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_response_debevec(w, L, Z, t_vec, E_ind, lambd):\n",
    "    '''\n",
    "    Estimates camera inverse response function values.\n",
    "\n",
    "    Parameters:\n",
    "    w (float): An array of shape (N,) of weights.\n",
    "    L (int): number of pixel intezity discrete levels\n",
    "    Z (numpy.ndarray): An array of shape (N,) containing the pixel intezities.\n",
    "    t_ind (numpy.ndarray): An array of shape (P, N,) containing the time indices.\n",
    "    Z_ind (numpy.ndarray): An array of shape (P, N,) containing the pixel intensities indices.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: An array of shape (L,) containing the estimated camera inverse response function values.\n",
    "    '''\n",
    "    \n",
    "    # YOUR estimate_response_debevec LOGIC HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T09:59:34.608597100Z",
     "start_time": "2023-10-15T09:59:30.231786100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lambda_ = 2\n",
    "g_r, _ = estimate_response_debevec(w_r, 2**8, r, t, Z_ind, lambda_)\n",
    "g_g, _ = estimate_response_debevec(w_g, 2**8, g, t, Z_ind, lambda_)\n",
    "g_b, _ = estimate_response_debevec(w_b, 2**8, b, t, Z_ind, lambda_)\n",
    "plt.plot(g_r, 'r')\n",
    "plt.plot(g_g, 'g')\n",
    "plt.plot(g_b, 'b')\n",
    "plt.title('Estimated camera inverse response functions values');\n",
    "plt.xlabel('Z')\n",
    "plt.ylabel('g()');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models of inverse response functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:09:26.824682600Z",
     "start_time": "2023-10-15T10:09:26.414754400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_response(L, g, degree=2):\n",
    "    g_val = []\n",
    "    for idx in range(L):\n",
    "        g_val.append([idx, g[idx]])\n",
    "    g_val = np.array(g_val)\n",
    "    \n",
    "    poly_transform = PolynomialFeatures(degree=degree, include_bias=False).fit(g_val[:,0].reshape((-1,1)))\n",
    "    poly_trans = lambda x: poly_transform.transform(x.reshape((-1,1)))\n",
    "    z_poly = poly_trans(g_val[:,0])\n",
    "    g_model = LinearRegression()\n",
    "    g_model.fit(z_poly, g_val[:,1])\n",
    "    g_model_pred = g_model.predict(poly_trans(g_val[:,0]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(x=g_val[:,0], y=g_val[:,1])\n",
    "    plt.plot(g_model_pred, 'r')\n",
    "    \n",
    "    return g_model_pred\n",
    "\n",
    "g_model_r = fit_response(2**8, g_r, degree=2)\n",
    "plt.title('Camera response function - red chanel')\n",
    "g_model_g = fit_response(2**8, g_g, degree=2)\n",
    "plt.title('Camera response function - green chanel')\n",
    "g_model_b = fit_response(2**8, g_b, degree=2)\n",
    "plt.title('Camera response function - blue chanel');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDR Composition - download full scale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    download_images(images_urls, tempdir)\n",
    "    dim_f, Z_f, t_f = read_images(os.path.join(tempdir, \"*.jpg\"), scale_percent = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pixel intesities to radiances - YOUR TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:22:23.024825900Z",
     "start_time": "2023-10-15T10:22:21.747401700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def hdr_from_exposure(g, w, Z, t):\n",
    "    w_img = np.sqrt(w.reshape((len(t),-1)))\n",
    "    Z_img = np.interp(Z, list(range(2**8)), g).reshape((len(t),-1))\n",
    "    E = np.zeros(w_img.shape[1], dtype=np.float32)\n",
    "    t = np.log(t)\n",
    "    \n",
    "    # YOUR pixel irradiance LOGIC HERE, don't forget return E instead of log(E)\n",
    "    \n",
    "    return E\n",
    "\n",
    "r_f = Z_f[:, :, :, 0].flatten() \n",
    "g_f = Z_f[:, :, :, 1].flatten() \n",
    "b_f = Z_f[:, :, :, 2].flatten() \n",
    "w_r_f = get_weights(r_f, L) \n",
    "w_g_f = get_weights(g_f, L) \n",
    "w_b_f = get_weights(b_f, L) \n",
    "\n",
    "E_r_est = hdr_from_exposure(g_model_r, w_r_f, r_f, t)\n",
    "E_g_est = hdr_from_exposure(g_model_g, w_g_f, g_f, t)\n",
    "E_b_est = hdr_from_exposure(g_model_b, w_b_f, b_f, t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show radiance maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:12.192137800Z",
     "start_time": "2023-10-15T10:10:11.905151Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.log(E_r_est.reshape(dim_f)))\n",
    "plt.colorbar()\n",
    "plt.title('Radiance map - red chanel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:15.015217500Z",
     "start_time": "2023-10-15T10:10:14.774182600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.log(E_g_est.reshape(dim_f)))\n",
    "plt.colorbar()\n",
    "plt.title('Radiance map - green chanel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:17.415962800Z",
     "start_time": "2023-10-15T10:10:17.167968Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.log(E_b_est.reshape(dim_f)))\n",
    "plt.colorbar()\n",
    "plt.title('Radiance map - blue chanel');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show HDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:20.100239600Z",
     "start_time": "2023-10-15T10:10:19.900219600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hdr = np.stack((E_r_est.reshape(dim_f), E_g_est.reshape(dim_f), E_b_est.reshape(dim_f)), axis=-1)\n",
    "plt.imshow(hdr)\n",
    "plt.title('HDR Image - clipped');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert HDR to LDR by linear tonemapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T10:10:31.208913100Z",
     "start_time": "2023-10-15T10:10:30.879319300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tonemap1 = cv2.createTonemap(gamma=1)\n",
    "res_debevec = tonemap1.process(np.log(hdr.copy()).astype(np.float32)\n",
    "res_debevec = np.clip(res_debevec*255, 0, 255).astype('uint8')\n",
    "plt.imshow(res_debevec)\n",
    "plt.title('Generated LDR image by linear tonemapping');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert HDR to LDR by logarithmic tonemapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdr_to_ldr_operator(radiance_map, b=0.5, ldmax=100):\n",
    "    max_radiance = np.max(radiance_map)\n",
    "    a = ldmax*0.01/np.log10(max_radiance+1)\n",
    "    c = np.log(b)/np.log(0.5)\n",
    "    ldr = a*np.log(radiance_map+1)/(np.log(2+(radiance_map/max_radiance)**c*8))\n",
    "    return ldr\n",
    "\n",
    "def log_tonemap(hdr, b=0.5, ldmax=100):\n",
    "    ldr = np.zeros(hdr.shape)\n",
    "    for idx in range(hdr.shape[-1]):\n",
    "        ldr[:,:,idx] = hdr_to_ldr_operator(hdr[:,:,idx], b, ldmax)\n",
    "    return np.clip(ldr*255, 0, 255).astype('uint8')\n",
    "\n",
    "ldr_debevec = log_tonemap(hdr_debevec, b=0.5, ldmax=70)\n",
    "plt.imshow(cv2.cvtColor(ldr_debevec, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
